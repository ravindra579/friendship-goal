{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599283415506",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import numpy as np\n",
    "from keras.layers import Dense,Dropout,Conv2D,BatchNormalization\n",
    "import os \n",
    "from cv2 import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Dropout, Conv2D,Conv2DTranspose, BatchNormalization, Activation,AveragePooling2D,Flatten,GlobalAveragePooling2D, Input, Concatenate, MaxPool2D, Add, UpSampling2D, LeakyReLU,ZeroPadding2D\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau,LearningRateScheduler\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path1=\"C:/Users/ravin/Documents/Dataset/train/Adults\"\n",
    "path2=\"C:/Users/ravin/Documents/Dataset/train/Teenagers\"\n",
    "path3=\"C:/Users/ravin/Documents/Dataset/train/Toddler\"\n",
    "files=[]\n",
    "labels=[]\n",
    "for file in os.listdir(path1):\n",
    "      if os.path.isfile(os.path.join(path1,file)):\n",
    "          files.append(os.path.join(path1,file))\n",
    "          labels.append(0)\n",
    "for file in os.listdir(path2):\n",
    "      if os.path.isfile(os.path.join(path2,file)):\n",
    "           files.append(os.path.join(path2,file))\n",
    "           labels.append(1)\n",
    "for file in os.listdir(path3):\n",
    "      if os.path.isfile(os.path.join(path3,file)):\n",
    "           files.append(os.path.join(path3,file))\n",
    "           labels.append(2)\n",
    "img=[]\n",
    "for i in range(len(files)):\n",
    "    img1=cv2.imread(files[i],1)\n",
    "    img2=np.array(img1)\n",
    "    img2=cv2.resize(img2,(128,128))\n",
    "    img.append(cv2.cvtColor(img2,cv2.COLOR_BGR2RGB))\n",
    "train_y=to_categorical(labels,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rotation_range=5,width_shift_range=0.15,height_shift_range=0.15,zoom_range=5)\n",
    "datagen.fit(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=img[0].shape))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.4))\n",
    "model_3.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.4))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(128, activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.4))\n",
    "model_3.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.005\n",
    "lrr=ReduceLROnPlateau(monitor=\"accuracy\",patience=2,verbose=1,factor=0.5,min_lr=0.000001)\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/60\n43/43 [==============================] - 276s 6s/step - loss: 1.6995 - accuracy: 0.3932\nEpoch 2/60\n43/43 [==============================] - 262s 6s/step - loss: 1.2561 - accuracy: 0.4984\nEpoch 3/60\n43/43 [==============================] - 260s 6s/step - loss: 1.0022 - accuracy: 0.5765\nEpoch 4/60\n43/43 [==============================] - 263s 6s/step - loss: 0.8463 - accuracy: 0.6550\nEpoch 5/60\n43/43 [==============================] - 232s 5s/step - loss: 0.7461 - accuracy: 0.6937\nEpoch 6/60\n43/43 [==============================] - 230s 5s/step - loss: 0.6276 - accuracy: 0.7492\nEpoch 7/60\n43/43 [==============================] - 229s 5s/step - loss: 0.5376 - accuracy: 0.7857\nEpoch 8/60\n43/43 [==============================] - 232s 5s/step - loss: 0.4510 - accuracy: 0.8237\nEpoch 9/60\n43/43 [==============================] - 237s 6s/step - loss: 0.3917 - accuracy: 0.8496\nEpoch 10/60\n43/43 [==============================] - 245s 6s/step - loss: 0.3463 - accuracy: 0.8667\nEpoch 11/60\n43/43 [==============================] - 244s 6s/step - loss: 0.3186 - accuracy: 0.8748\nEpoch 12/60\n43/43 [==============================] - 248s 6s/step - loss: 0.2919 - accuracy: 0.8894\nEpoch 13/60\n43/43 [==============================] - 257s 6s/step - loss: 0.2595 - accuracy: 0.9032\nEpoch 14/60\n43/43 [==============================] - 230s 5s/step - loss: 0.2219 - accuracy: 0.9208\nEpoch 15/60\n43/43 [==============================] - 231s 5s/step - loss: 0.2264 - accuracy: 0.9211\nEpoch 16/60\n43/43 [==============================] - 228s 5s/step - loss: 0.2018 - accuracy: 0.9292\nEpoch 17/60\n43/43 [==============================] - 229s 5s/step - loss: 0.1837 - accuracy: 0.9325\nEpoch 18/60\n43/43 [==============================] - 230s 5s/step - loss: 0.1594 - accuracy: 0.9460\nEpoch 19/60\n43/43 [==============================] - 230s 5s/step - loss: 0.1446 - accuracy: 0.9511\nEpoch 20/60\n43/43 [==============================] - 262s 6s/step - loss: 0.1371 - accuracy: 0.9555\nEpoch 21/60\n43/43 [==============================] - 254s 6s/step - loss: 0.1331 - accuracy: 0.9555\nEpoch 22/60\n43/43 [==============================] - 243s 6s/step - loss: 0.1216 - accuracy: 0.9606\nEpoch 23/60\n43/43 [==============================] - 246s 6s/step - loss: 0.1217 - accuracy: 0.9573\nEpoch 24/60\n43/43 [==============================] - 247s 6s/step - loss: 0.1097 - accuracy: 0.9657\nEpoch 25/60\n43/43 [==============================] - 244s 6s/step - loss: 0.0988 - accuracy: 0.9697\nEpoch 26/60\n43/43 [==============================] - 237s 6s/step - loss: 0.1050 - accuracy: 0.9660\nEpoch 27/60\n43/43 [==============================] - 225s 5s/step - loss: 0.0794 - accuracy: 0.9785\nEpoch 28/60\n43/43 [==============================] - 227s 5s/step - loss: 0.0948 - accuracy: 0.9686\nEpoch 29/60\n43/43 [==============================] - 226s 5s/step - loss: 0.0892 - accuracy: 0.9701\nEpoch 30/60\n43/43 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9726\nEpoch 00030: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n43/43 [==============================] - 224s 5s/step - loss: 0.0853 - accuracy: 0.9726\nEpoch 31/60\n43/43 [==============================] - 224s 5s/step - loss: 0.0773 - accuracy: 0.9748\nEpoch 32/60\n43/43 [==============================] - 224s 5s/step - loss: 0.0734 - accuracy: 0.9788\nEpoch 33/60\n43/43 [==============================] - 226s 5s/step - loss: 0.0673 - accuracy: 0.9806\nEpoch 34/60\n43/43 [==============================] - 225s 5s/step - loss: 0.0657 - accuracy: 0.9817\nEpoch 35/60\n43/43 [==============================] - 225s 5s/step - loss: 0.0628 - accuracy: 0.9796\nEpoch 36/60\n43/43 [==============================] - 226s 5s/step - loss: 0.0558 - accuracy: 0.9861\nEpoch 37/60\n43/43 [==============================] - 225s 5s/step - loss: 0.0679 - accuracy: 0.9777\nEpoch 38/60\n43/43 [==============================] - 207s 5s/step - loss: 0.0567 - accuracy: 0.9825\nEpoch 39/60\n43/43 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9836\nEpoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n43/43 [==============================] - 190s 4s/step - loss: 0.0571 - accuracy: 0.9836\nEpoch 40/60\n43/43 [==============================] - 197s 5s/step - loss: 0.0573 - accuracy: 0.9854\nEpoch 41/60\n43/43 [==============================] - 229s 5s/step - loss: 0.0531 - accuracy: 0.9858\nEpoch 42/60\n43/43 [==============================] - 231s 5s/step - loss: 0.0447 - accuracy: 0.9869\nEpoch 43/60\n43/43 [==============================] - 233s 5s/step - loss: 0.0463 - accuracy: 0.9898\nEpoch 44/60\n43/43 [==============================] - 222s 5s/step - loss: 0.0486 - accuracy: 0.9880\nEpoch 45/60\n43/43 [==============================] - 206s 5s/step - loss: 0.0480 - accuracy: 0.9873\nEpoch 46/60\n43/43 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9854\nEpoch 00046: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n43/43 [==============================] - 217s 5s/step - loss: 0.0525 - accuracy: 0.9854\nEpoch 47/60\n43/43 [==============================] - 206s 5s/step - loss: 0.0489 - accuracy: 0.9843\nEpoch 48/60\n43/43 [==============================] - 231s 5s/step - loss: 0.0440 - accuracy: 0.9887\nEpoch 49/60\n43/43 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9883\nEpoch 00049: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n43/43 [==============================] - 205s 5s/step - loss: 0.0427 - accuracy: 0.9883\nEpoch 50/60\n43/43 [==============================] - 212s 5s/step - loss: 0.0457 - accuracy: 0.9865\nEpoch 51/60\n43/43 [==============================] - 228s 5s/step - loss: 0.0419 - accuracy: 0.9905\nEpoch 52/60\n43/43 [==============================] - 230s 5s/step - loss: 0.0401 - accuracy: 0.9905\nEpoch 53/60\n43/43 [==============================] - 227s 5s/step - loss: 0.0471 - accuracy: 0.9869\nEpoch 54/60\n43/43 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9887\nEpoch 00054: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n43/43 [==============================] - 233s 5s/step - loss: 0.0419 - accuracy: 0.9887\nEpoch 55/60\n43/43 [==============================] - 242s 6s/step - loss: 0.0494 - accuracy: 0.9869\nEpoch 56/60\n43/43 [==============================] - 242s 6s/step - loss: 0.0422 - accuracy: 0.9887\nEpoch 57/60\n43/43 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9883\nEpoch 00057: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n43/43 [==============================] - 242s 6s/step - loss: 0.0425 - accuracy: 0.9883\nEpoch 58/60\n43/43 [==============================] - 241s 6s/step - loss: 0.0399 - accuracy: 0.9898\nEpoch 59/60\n43/43 [==============================] - 243s 6s/step - loss: 0.0415 - accuracy: 0.9894\nEpoch 60/60\n43/43 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9894\nEpoch 00060: ReduceLROnPlateau reducing learning rate to 1e-06.\n43/43 [==============================] - 227s 5s/step - loss: 0.0402 - accuracy: 0.9894\n"
    }
   ],
   "source": [
    "model_3.compile(optimizer=Adam(lr=learning_rate),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "hist=model_3.fit(np.array(img),train_y,batch_size=64,epochs=60,steps_per_epoch=len(files)//batch_size,verbose=1,callbacks=[lrr])\n",
    "model_3.save_weights(\"dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.load_weights(\"dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n 9/43 [=====>........................] - ETA: 2:45 - loss: 1.9026 - accuracy: 0.4618"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-175ccdd0eea6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlrr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset_1.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1098\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    784\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    811\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2855\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2856\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2857\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2859\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1848\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m     \"\"\"\n\u001b[1;32m-> 1850\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1851\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1852\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1928\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1929\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1930\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1931\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1932\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    547\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    550\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer=Adam(lr=learning_rate),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "hist=model_3.fit(np.array(img),train_y,batch_size=64,epochs=5,steps_per_epoch=len(files)//batch_size,verbose=1,callbacks=[lrr])\n",
    "model_3.save_weights(\"dataset_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'src'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-6388902e4bcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimg2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mimg2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'src'"
     ]
    }
   ],
   "source": [
    "test=pandas.read_csv(\"C:/Users/ravin/Documents/Dataset/test.csv\")\n",
    "id=test.Filename\n",
    "test_imgs=[]\n",
    "for i in range(len(id)):\n",
    "    test_imgs.append(\"C:/Users/ravin/Documents/Dataset/test\"+id[1]+\".jpg\")\n",
    "test_img=[]\n",
    "for i in range(len(id)):\n",
    "    img1=cv2.imread(test_imgs[i],1)\n",
    "    img2=np.array(img1)\n",
    "    img2=cv2.resize(img2,(128,128))\n",
    "    img.append(cv2.cvtColor(img2,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}